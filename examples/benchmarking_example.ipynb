{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking of Optimization Algorithms\n",
    "\n",
    "This IJulia notebook goes through the steps to benchmark various optimization algorithms using random tensor networks. [Results](#report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/Qaintum/Qaintessent.jl`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `/import/home/ga53vuw/Documents/PhD/projects/QAI/Qaintensor.jl/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `/import/home/ga53vuw/Documents/PhD/projects/QAI/Qaintensor.jl/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "] add https://github.com/Qaintum/Qaintessent.jl#view-matrix-gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Test\n",
    "using TestSetExtensions \n",
    "using Qaintessent\n",
    "using Qaintensor\n",
    "using BenchmarkTools\n",
    "using LinearAlgebra\n",
    "using StatsBase: sample\n",
    "using TensorOperations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "    \n",
    "Defining helper functions to create random unitary gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rand_local_g (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function shift_summation(S::Summation, step::Integer)\n",
    "   return Summation([S.idx[i].first + step => S.idx[i].second for i in 1:2])\n",
    "end\n",
    "\n",
    "function shift_pair(P::Pair{Integer, Integer}, step::Integer)\n",
    "    return P.first + step => P.second\n",
    "end\n",
    "\n",
    "function rand_U(M)\n",
    "    U, _ = qr(rand(ComplexF64, 2^M, 2^M))\n",
    "    @assert U*adjoint(U) ≈ I\n",
    "    return Array(U)\n",
    "end\n",
    "\n",
    "# Random unitary matrix in M\n",
    "function rand_local_g(M, N, max_d)\n",
    "    @assert M ≤ max_d ≤ N\n",
    "    U = rand_U(M)\n",
    "    dist = rand()\n",
    "    iwire = sort(sample(1:max_d, M, replace = false))\n",
    "    m1 = rand(0:N-maximum(iwire))\n",
    "    iwire .+= m1\n",
    "\n",
    "    return CircuitGate{M, N, AbstractGate{M}}(Tuple(iwire), MatrixGate(U))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Log Depth Tensor Network\n",
    "\n",
    "Define `log_depth_TN`. This function creates a random logarithmic depth tensor network composed of random unitary gates. Note that the ends of this randomly generated tensor networks are 1-Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_depth_TN (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function log_depth_TN(M, N, C)\n",
    "    Nlayers = C*Int(round(log2(N)))\n",
    "    gates = AbstractCircuitGate{N}[]\n",
    "    for j in 1:Nlayers\n",
    "        itergates = (j%2 == 1) ? (1:M:N-M+1) : (M:M:N-M+1)\n",
    "        for i in itergates\n",
    "            U = rand_U(M)\n",
    "            g = CircuitGate{M, N, AbstractGate{M}}(Tuple(collect(i:i+M-1)), MatrixGate(U))\n",
    "            push!(gates, g)\n",
    "        end\n",
    "    end\n",
    "    cgc = CircuitGateChain{N}(gates)\n",
    "    # make tensor network\n",
    "\n",
    "    tensors = Tensor.([[1,0] for i in 1:N])\n",
    "    contractions = Summation[]\n",
    "    openidx = [i => 1 for i in 1:N]\n",
    "    T = TensorNetwork(tensors, contractions, openidx)\n",
    "\n",
    "    tensor_circuit!(T, cgc)\n",
    "    # measure\n",
    "    for i in 1:N\n",
    "        push!(T.tensors, deepcopy(T.tensors[N+1-i]))\n",
    "        push!(T.contractions, Summation([T.openidx[end], length(T.tensors) => 1]))\n",
    "        pop!(T.openidx)\n",
    "    end\n",
    "    T, cgc\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning contraction optimization for log depth TN circuit\u001b[39m\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  21.403 μs (199 allocations: 10.42 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.036493 seconds (17.96 k allocations: 947.227 KiB)\n",
      "  22.557 μs (209 allocations: 11.48 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.518001 seconds (1.10 M allocations: 52.986 MiB, 1.22% gc time)\n",
      "  22.299 μs (209 allocations: 11.48 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  39.232 μs (359 allocations: 19.98 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.000511 seconds (25.90 k allocations: 1.594 MiB)\n",
      "  39.126 μs (352 allocations: 19.27 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.162353 seconds (450.99 k allocations: 22.284 MiB)\n",
      "  37.765 μs (362 allocations: 20.33 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  56.189 μs (510 allocations: 29.13 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.003387 seconds (168.42 k allocations: 10.358 MiB)\n",
      "  59.955 μs (513 allocations: 28.88 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.002553 seconds (2.32 k allocations: 141.391 KiB)\n",
      "  53.366 μs (485 allocations: 26.31 KiB)\n"
     ]
    }
   ],
   "source": [
    "printstyled(\"\\nRunning contraction optimization for log depth TN circuit\\n\"; color=:green)\n",
    "for N in 2:4\n",
    "    Ngates = 10\n",
    "    M = 2\n",
    "    max_d = 3\n",
    "    ψ, cgc = log_depth_TN(M, N, 1);\n",
    "\n",
    "    printstyled(\"\\nBaseline contraction\\n\"; color=:yellow)\n",
    "    ref = contract(ψ)\n",
    "    printstyled(\"opt_einsum contraction\\n\"; color=:yellow)\n",
    "    einsum_ans = contract(ψ; optimize=true)\n",
    "    printstyled(\"treewidth contraction\\n\"; color=:yellow)\n",
    "    printstyled(\"  time for treewidth optimization: \"; color=:blue)\n",
    "    @time optimize_contraction_order!(ψ)\n",
    "    opt_ans = contract(ψ)\n",
    "\n",
    "    @test ref ≈ einsum_ans\n",
    "    @test ref ≈ opt_ans\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Tensor Network\n",
    "\n",
    "Define `rand_local_TN`. This function creates a random tensor network composed of random unitary gates. Note that the ends of this randomly generated tensor networks are 1-Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rand_local_TN (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rand_local_TN(M, N, max_d, Ngates)\n",
    "\n",
    "    tensors = Tensor.([[1,0] for i in 1:N])\n",
    "    contractions = Summation[]\n",
    "    openidx = [i => 1 for i in 1:N]\n",
    "    T = TensorNetwork(tensors, contractions, openidx)\n",
    "\n",
    "    cgc = CircuitGateChain{N}([rand_local_g(M, N, max_d) for i in 1:Ngates])\n",
    "\n",
    "    tensor_circuit!(T, cgc)\n",
    "    # measure\n",
    "    for i in 1:N\n",
    "        push!(T.tensors, deepcopy(T.tensors[N+1-i]))\n",
    "        push!(T.contractions, Summation([T.openidx[end], length(T.tensors) => 1]))\n",
    "        pop!(T.openidx)\n",
    "    end\n",
    "    T, cgc\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning contraction optimization for random TN circuit\u001b[39m\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  61.912 μs (562 allocations: 35.00 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.009440 seconds (225.14 k allocations: 13.781 MiB, 57.13% gc time)\n",
      "  63.530 μs (572 allocations: 36.06 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.003218 seconds (8.42 k allocations: 528.672 KiB)\n",
      "  66.257 μs (588 allocations: 37.63 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  81.656 μs (729 allocations: 45.53 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.024201 seconds (984.14 k allocations: 60.345 MiB, 23.10% gc time)\n",
      "  80.108 μs (674 allocations: 41.47 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000455 seconds (9.04 k allocations: 568.578 KiB)\n",
      "  81.048 μs (690 allocations: 43.03 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  99.031 μs (877 allocations: 56.64 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.037528 seconds (1.40 M allocations: 85.703 MiB, 28.82% gc time)\n",
      "  96.301 μs (802 allocations: 50.66 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000473 seconds (9.84 k allocations: 617.766 KiB)\n",
      "  93.011 μs (787 allocations: 48.80 KiB)\n"
     ]
    }
   ],
   "source": [
    "printstyled(\"\\nRunning contraction optimization for random TN circuit\\n\"; color=:green)\n",
    "for N in 2:4\n",
    "    Ngates = 10\n",
    "    M = 2\n",
    "    max_d = minimum([3, N])\n",
    "    ψ, cgc = rand_local_TN(M, N, max_d, Ngates)\n",
    "\n",
    "    printstyled(\"\\nBaseline contraction\\n\"; color=:yellow)\n",
    "    ref = contract(ψ)\n",
    "    printstyled(\"opt_einsum contraction\\n\"; color=:yellow)\n",
    "    einsum_ans = contract(ψ; optimize=true)\n",
    "    printstyled(\"treewidth contraction\\n\"; color=:yellow)\n",
    "    printstyled(\"  time for treewidth optimization: \"; color=:blue)\n",
    "    @time optimize_contraction_order!(ψ)\n",
    "    opt_ans = contract(ψ)\n",
    "\n",
    "    @test ref ≈ einsum_ans\n",
    "    @test ref ≈ opt_ans\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Log Depth MPS\n",
    "\n",
    "Define `log_depth_mps_TN`. This function creates a random tensor network composed of random unitary gates. Note that these circuits contract to an expectation value (single scalar end value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_depth_mps_TN (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function log_depth_mps_TN(M, N, C)\n",
    "    Nlayers = C*Int(round(log2(N)))\n",
    "    gates = AbstractCircuitGate{N}[]\n",
    "    for j in 1:Nlayers\n",
    "        itergates = (j%2 == 1) ? (1:M:N-M+1) : (M:M:N-M+1)\n",
    "        for i in itergates\n",
    "            U = rand_U(M)\n",
    "            g = CircuitGate{M, N, AbstractGate{M}}(Tuple(collect(i:i+M-1)), MatrixGate(U))\n",
    "            push!(gates, g)\n",
    "        end\n",
    "    end\n",
    "    cgc = CircuitGateChain{N}(gates)\n",
    "    # make tensor network\n",
    "\n",
    "    T = TensorNetwork([], [], [])\n",
    "    # oldbond = abs(rand(Int, 1)[1] % 10) + 2\n",
    "    oldbond = 5\n",
    "    push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond))))\n",
    "    for i in 1:N-2\n",
    "        # newbond = abs(rand(Int, 1)[1] % 10)  + 2\n",
    "        newbond = 5\n",
    "        push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond, newbond))))\n",
    "        oldbond = newbond\n",
    "    end\n",
    "    push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond))))\n",
    "\n",
    "    # contract virtual legs\n",
    "    push!(T.contractions, Summation([1=>2, 2=>2]))\n",
    "    for i in 2:N-1\n",
    "        push!(T.contractions, Summation([i=>3, i+1=>2]))\n",
    "    end\n",
    "\n",
    "    for i in 1:N\n",
    "        push!(T.openidx, i=>1)\n",
    "    end\n",
    "\n",
    "    tensor_circuit!(T, cgc)\n",
    "    T_prime = TensorNetwork(copy(T.tensors), copy(T.contractions), copy(T.openidx) )\n",
    "\n",
    "    l = length(T.tensors)\n",
    "    step = length(T_prime.tensors)\n",
    "    for i in 1:l\n",
    "        push!(T_prime.tensors, conj(T.tensors[i]))\n",
    "    end\n",
    "\n",
    "    for i in 1:length(T.openidx)\n",
    "        push!(T_prime.contractions, Summation([T_prime.openidx[i], shift_pair(T.openidx[i], step)]))\n",
    "    end\n",
    "\n",
    "    for (i, con) in enumerate(T.contractions)\n",
    "        push!(T_prime.contractions, shift_summation(con, step))\n",
    "    end\n",
    "\n",
    "    T_prime.openidx=Pair[]\n",
    "\n",
    "    T, cgc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning contraction optimization for log depth MPS circuit\u001b[39m\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  11.163 μs (90 allocations: 5.67 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.000018 seconds (387 allocations: 23.719 KiB)\n",
      "  11.172 μs (90 allocations: 5.67 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000090 seconds (387 allocations: 23.547 KiB)\n",
      "  12.384 μs (110 allocations: 8.09 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  25.716 μs (211 allocations: 14.25 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.000123 seconds (5.19 k allocations: 323.547 KiB)\n",
      "  25.632 μs (211 allocations: 13.77 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000137 seconds (1.09 k allocations: 67.844 KiB)\n",
      "  33.671 μs (242 allocations: 32.39 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  40.205 μs (351 allocations: 27.42 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.000849 seconds (35.67 k allocations: 2.185 MiB)\n",
      "  39.608 μs (340 allocations: 25.34 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000317 seconds (2.08 k allocations: 130.516 KiB)\n",
      "  48.445 μs (372 allocations: 28.50 KiB)\n"
     ]
    }
   ],
   "source": [
    "printstyled(\"\\nRunning contraction optimization for log depth MPS circuit\\n\"; color=:green)\n",
    "for N in 2:4\n",
    "    Ngates = 10\n",
    "    M = 2\n",
    "    max_d = 3\n",
    "    ψ, cgc = log_depth_mps_TN(M, N, 1);\n",
    "\n",
    "    printstyled(\"\\nBaseline contraction\\n\"; color=:yellow)\n",
    "    ref = contract(ψ)\n",
    "    printstyled(\"opt_einsum contraction\\n\"; color=:yellow)\n",
    "    einsum_ans = contract(ψ; optimize=true)\n",
    "    printstyled(\"treewidth contraction\\n\"; color=:yellow)\n",
    "    printstyled(\"  time for treewidth optimization: \"; color=:blue)\n",
    "    @time optimize_contraction_order!(ψ)\n",
    "    opt_ans = contract(ψ)\n",
    "\n",
    "    @test ref ≈ einsum_ans\n",
    "    @test ref ≈ opt_ans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4: Random MPS\n",
    "\n",
    "Define `log_depth_mps_TN`. This function creates a random tensor network composed of random unitary gates. Note that these circuits contract to an expectation value (single scalar end value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rand_local_mps_TN (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rand_local_mps_TN(M, N, max_d, Ngates)\n",
    "\n",
    "    T = TensorNetwork([], [], [])\n",
    "    oldbond = abs(rand(Int, 1)[1] % 10) + 2\n",
    "    push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond))))\n",
    "    for i in 1:N-2\n",
    "        newbond = abs(rand(Int, 1)[1] % 10)  + 2\n",
    "        push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond, newbond))))\n",
    "        oldbond = newbond\n",
    "    end\n",
    "    push!(T.tensors, Tensor(randn(ComplexF64, (2, oldbond))))\n",
    "    # contract virtual legs\n",
    "    push!(T.contractions, Summation([1=>2, 2=>2]))\n",
    "    for i in 2:N-1\n",
    "        push!(T.contractions, Summation([i=>3, i+1=>2]))\n",
    "    end\n",
    "    for i in 1:N\n",
    "        push!(T.openidx, i=>1)\n",
    "    end\n",
    "\n",
    "    cgc = CircuitGateChain{N}([rand_local_g(M, N, max_d) for i in 1:Ngates])\n",
    "\n",
    "    tensor_circuit!(T, cgc)\n",
    "\n",
    "    T_prime = TensorNetwork(copy(T.tensors), copy(T.contractions), copy(T.openidx) )\n",
    "\n",
    "    l = length(T.tensors)\n",
    "    step = length(T_prime.tensors)\n",
    "    for i in 1:l\n",
    "        push!(T_prime.tensors, conj(T.tensors[i]))\n",
    "    end\n",
    "\n",
    "    for i in 1:length(T.openidx)\n",
    "        push!(T_prime.contractions, Summation([T_prime.openidx[i], shift_pair(T.openidx[i], step)]))\n",
    "    end\n",
    "\n",
    "    for (i, con) in enumerate(T.contractions)\n",
    "        push!(T_prime.contractions, shift_summation(con, step))\n",
    "    end\n",
    "\n",
    "    T_prime.openidx=Pair[]\n",
    "\n",
    "    T, cgc\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning contraction optimization for random MPS circuit\u001b[39m\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  53.061 μs (462 allocations: 30.38 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.008502 seconds (89.84 k allocations: 5.488 MiB, 78.91% gc time)\n",
      "  52.926 μs (462 allocations: 30.38 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000494 seconds (7.72 k allocations: 485.266 KiB)\n",
      "  57.798 μs (497 allocations: 34.86 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  68.523 μs (636 allocations: 44.58 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.010963 seconds (530.83 k allocations: 32.512 MiB)\n",
      "  68.284 μs (636 allocations: 43.66 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000541 seconds (9.51 k allocations: 632.516 KiB)\n",
      "  97.772 μs (720 allocations: 68.78 KiB)\n",
      "\n",
      "\u001b[33mBaseline contraction\u001b[39m\n",
      "  77.957 μs (714 allocations: 56.30 KiB)\n",
      "\u001b[33mopt_einsum contraction\u001b[39m\n",
      "\u001b[34m  time for opt_einsum optimization: \u001b[39m  0.059843 seconds (1.77 M allocations: 108.592 MiB, 31.80% gc time)\n",
      "  77.904 μs (723 allocations: 55.53 KiB)\n",
      "\u001b[33mtreewidth contraction\u001b[39m\n",
      "\u001b[34m  time for treewidth optimization: \u001b[39m  0.000524 seconds (10.23 k allocations: 691.172 KiB)\n",
      "  115.837 μs (766 allocations: 85.81 KiB)\n"
     ]
    }
   ],
   "source": [
    "printstyled(\"\\nRunning contraction optimization for random MPS circuit\\n\"; color=:green)\n",
    "for N in 2:4\n",
    "    Ngates = 10\n",
    "    M = 2\n",
    "    max_d = minimum([3, N])\n",
    "    ψ, cgc = rand_local_mps_TN(M, N, max_d, Ngates);\n",
    "\n",
    "    printstyled(\"\\nBaseline contraction\\n\"; color=:yellow)\n",
    "    ref = contract(ψ)\n",
    "    printstyled(\"opt_einsum contraction\\n\"; color=:yellow)\n",
    "    einsum_ans = contract(ψ; optimize=true)\n",
    "    printstyled(\"treewidth contraction\\n\"; color=:yellow)\n",
    "    printstyled(\"  time for treewidth optimization: \"; color=:blue)\n",
    "    @time optimize_contraction_order!(ψ)\n",
    "    opt_ans = contract(ψ)\n",
    "\n",
    "    @test ref ≈ einsum_ans\n",
    "    @test ref ≈ opt_ans\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".jl",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
